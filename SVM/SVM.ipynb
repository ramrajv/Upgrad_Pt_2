{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOUDMmYZfSLdDZU3NrWF4AU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramrajv/Upgrad_Pt_2/blob/main/SVM/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM\n",
        "## Introduction\n",
        "Support Vector Machines, or SVMs, are a class of extremely popular classification models. Besides their ability to solve complex machine learning problems, they have numerous other advantages over other classification problems, such as the ability to deal with computationally heavy data sets, classifying nonlinearly separable data, etc. \n",
        "\n",
        "**SVMs belong to the class of linear machine learning models (logistic regression is also a linear model).**\n",
        "\n",
        "A linear model uses a linear function (i.e. of the form y = ax +b) to model the relationship between the input x and output y. For example, in logistic regression, the log(odds) of an outcome (say, defaulting on a credit card) is linearly related to the attributes x1, x2, etc.\n",
        "\n",
        "$log(odds of default) = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + ......\\beta_{n}X_{n}$\n",
        "\n"
      ],
      "metadata": {
        "id": "ny2oVvHMjBzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVMs need attributes in the numeric form. In our (somewhat simplified) example of email classification, the features are the ‘frequency of words’ in an email. Word frequency is a very common type of feature in text classification, and reasonably so. For example, words such as ‘Hurry’, ‘FREE’ and ‘Discount’ are likely to be more frequent in spam emails than ‘meeting’, ‘PPT’, ‘weekly report’, and others that are characteristic of office emails. "
      ],
      "metadata": {
        "id": "33jHtljks30r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/ramrajv/Study_Group/main/SVM/Spam.csv'\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "mDGMddzntKOy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concept of a Hyperplane in 2D\n",
        "Before you move on to support vector machines, you need to understand the concept of hyperplanes. Essentially, it is a boundary which 'separates' the data set into its classes (in this case, separates spam emails from the ham ones). It could be lines, 2D planes, or even n-dimensional planes that are beyond our imagination."
      ],
      "metadata": {
        "id": "nhQYT9FAs5Rn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A line that is used to classify one class from another is also called a hyperplane.\n",
        "\n",
        "The standard equation of a line is given by ax+by+c = 0. You could generalise it as $W_{0} + W_{1}x_{1} + W_{2}x_{2} = 0$, where x1 and x2 are the features — such as 'word_freq_technology' and 'word_freq_money' — and W1 and W2 are the coefficients. For any line with W coefficients, substituting the value of features x1 and x2 in the equation of the line determined by its W coefficients, will return a value. \n",
        "\n",
        "A positive value  would mean that the set of values of the features is in one class; however, a negative value (red points in the plot above) would imply it belongs to the other class. A value of zero would imply that the point lies on the line (hyperplane) because any point on the line will satisfy the equation: $W_{0} + W_{1}x_{1} + W_{2}x_{2} = 0$."
      ],
      "metadata": {
        "id": "4w6alSMiuI4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distance of a point from a hyperplane\n",
        "\n",
        "$d = \\frac{W_{0} + W_{1}x_{1}'+W_{2}x_{2}'}{\\sqrt{W_{1}^2 + W_{2}^{2}}}$\n",
        "\n",
        "can be represented as $d = \\overrightarrow{W}.\\overrightarrow{y_{i}}$\n",
        "\n",
        "For n dimensions, the distance formula is\n",
        "\n",
        "$d = \\frac{W_{0} + \\sum_{i=1}^n{W_{i}x_{i}}}{\\sqrt\\sum_{i=1}^n{{W_{i}^2}}}$"
      ],
      "metadata": {
        "id": "UMTL4TYixr7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to find the maximum margin classifier mathematically\n",
        "\n"
      ],
      "metadata": {
        "id": "otYG9zAR3J9i"
      }
    }
  ]
}